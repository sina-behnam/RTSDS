{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from train import val        \n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from static_definer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sample_image, source_sample_label  = next(iter(train_dataloader))\n",
    "target_sample_image, _  = next(iter(train_dataloaderGTA5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.domain_shift.adversarial.functions import DomainDiscriminator\n",
    "from models.bisenet.build_bisenet import BiSeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # defining a CrossEntropyLoss for the segmentation and a BCEWithLogitsLoss for the domain classification\n",
    "generator_loss = nn.CrossEntropyLoss(ignore_index=19)\n",
    "discriminator_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# defining the models\n",
    "generator = BiSeNet(num_classes=num_classes,context_path='resnet18',with_interpolation=True)\n",
    "# defining the Discriminator\n",
    "discriminator = DomainDiscriminator(num_classes=num_classes,with_grl=False)\n",
    "\n",
    "# defining the optimizer\n",
    "generator_optimizer = torch.optim.SGD(generator.parameters(), lr=1e-2, momentum=0.9, weight_decay=5e-4)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer.zero_grad()\n",
    "discriminator_optimizer.zero_grad()\n",
    "\n",
    "source_input_size = source_sample_image.size()[2:]\n",
    "target_input_size = target_sample_image.size()[2:]\n",
    "# These interpolation are defined to resizing the output of the discriminator\n",
    "source_interp = nn.Upsample(size=(source_input_size[1], source_input_size[0]), mode='bilinear')\n",
    "target_interp = nn.Upsample(size=(target_input_size[1], target_input_size[0]), mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss_calculator(criteria, model_output, segment_label):\n",
    "    '''\n",
    "    This function calculates the loss of the generator model\n",
    "    :param criteria: the loss function to be used\n",
    "    :param model_output: the output of the model\n",
    "    :param segment_label: the ground truth label\n",
    "\n",
    "    :return: the loss\n",
    "    '''\n",
    "\n",
    "    if isinstance(model_output,tuple):\n",
    "        model_output, ax1, ax2 = model_output\n",
    "        loss = criteria(model_output, segment_label)\n",
    "        loss += criteria(ax1, segment_label)\n",
    "        loss += criteria(ax2, segment_label)\n",
    "    else:\n",
    "        loss = criteria(model_output, segment_label)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch : int,lambda_=0.1):\n",
    "\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if get_ipython():\n",
    "            from tqdm.notebook import tqdm\n",
    "    except:\n",
    "        from tqdm import tqdm\n",
    "\n",
    "\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    for i, (source_data, target_data) in tqdm(enumerate(zip(train_dataloaderGTA5, train_dataloader)), total=len(train_dataloaderGTA5) , desc=f'Epoch {epoch}'):\n",
    "        source_image, source_label = source_data\n",
    "        target_image, _ = target_data\n",
    "\n",
    "        source_image, source_label = source_image.to(device), source_label.to(device)\n",
    "        target_image = target_image.to(device)\n",
    "\n",
    "        # ! Training the generator\n",
    "        generator_optimizer.zero_grad()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass Generator\n",
    "        # * The source features in here are same as the segmentation output as the low-dimenssion segmentation has been used as input of discriminator \n",
    "        source_features = generator(source_image)\n",
    "        target_feature = generator(target_image)\n",
    "\n",
    "        # loss on generator of source domain \n",
    "        # * We only perform the loss on the source domain as the target domain is not labeled\n",
    "        gen_source_loss = generator_loss_calculator(generator_loss, source_features, source_label)\n",
    "\n",
    "        if isinstance(source_features,tuple):\n",
    "            source_features, _ , _ = source_features\n",
    "        if isinstance(target_feature,tuple):\n",
    "            target_feature, _ , _ = target_feature\n",
    "        \n",
    "        # ! Forward pass Discriminator\n",
    "        # * Here we feed the Discriminator with the output of the generator (features) or in this case the (low-dimenssion segmentation)\n",
    "        source_discriminator_output = source_interp(discriminator(F.softmax(source_features)))\n",
    "        target_discriminator_output = target_interp(discriminator(F.softmax(target_feature)))\n",
    "        # * defining the Target label as 0 and the Source label as 1\n",
    "        source_label = torch.ones_like(source_discriminator_output)\n",
    "        target_label = torch.zeros_like(target_discriminator_output)\n",
    "\n",
    "        # loss on discriminator\n",
    "        disc_loss = discriminator_loss(source_discriminator_output, source_label) + discriminator_loss(target_discriminator_output, target_label)\n",
    "        \n",
    "        # ! Adversarial Training\n",
    "        target_feature, _, _ = generator(target_image)\n",
    "        target_discriminator_output = target_interp(discriminator(F.softmax(target_feature)))\n",
    "        # * To fool the discriminator\n",
    "        adver_loss = discriminator_loss(target_discriminator_output, source_label)\n",
    "        # total loss\n",
    "        total_loss = gen_source_loss + lambda_ * ( disc_loss + adver_loss )\n",
    "        total_loss.backward()\n",
    "        # Update the weights\n",
    "        generator_optimizer.step()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        if i % 100 == 0 and i != 0:\n",
    "            print(f'Iteration {i}, Generator Loss: {gen_source_loss.item()}, Discriminator Loss: {disc_loss.item()} , Adversarial Loss: {adver_loss.item()} , Total Loss: {total_loss.item()}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 10):\n",
    "\n",
    "    train(epoch,lambda_=0.1)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print('-'*50)\n",
    "        val(epoch, generator, generator_loss, num_classes, device, val_dataloader, 'GTA5')\n",
    "        print('-'*50)\n",
    "\n",
    "torch.save(generator.state_dict(), f'generator_{epoch}.pth')\n",
    "torch.save(discriminator.state_dict(), f'discriminator_{epoch}.pth')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
